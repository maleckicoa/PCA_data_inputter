{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37852d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class PcaInputter:\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        if not isinstance(data, (pd.DataFrame, np.ndarray)):\n",
    "            raise Exception(\"Input data must be a pandas DataFrame or a numpy array.\")\n",
    "        \n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            if not all(data.applymap(np.isreal).all()):\n",
    "                raise Exception(\"All values in the DataFrame must be numerical.\")\n",
    "            \n",
    "            if data.apply(lambda row: row.isnull().all(), axis=1).any():\n",
    "                raise Exception(\"Found a row where all columns are NaN in DataFrame.\")\n",
    "        \n",
    "            if data.apply(lambda col: col.isnull().all(), axis=0).any():\n",
    "                raise Exception(\"Found a column where all rows are NaN in DataFrame.\")\n",
    "            \n",
    "            else:\n",
    "                self.r_idx, self.c_idx = np.where(data.isnull())\n",
    "     \n",
    "        if isinstance(data, np.ndarray):\n",
    "            if not np.isreal(data).all():\n",
    "                raise Exception(\"All values in the numpy array must be numerical.\")\n",
    "                \n",
    "            if np.all(np.isnan(data), axis=1).any():\n",
    "                raise Exception(\"Found a row where all columns are NaN in numpy array.\")\n",
    "        \n",
    "            if np.all(np.isnan(data), axis=0).any():\n",
    "                raise Exception(\"Found a column where all rows are NaN in numpy array.\")\n",
    "    \n",
    "            else:\n",
    "                self.r_idx, self.c_idx = np.where(np.isnan(data))\n",
    "\n",
    "        self.na_data = data\n",
    "        \n",
    "\n",
    "    def run_pca(self, X, M):\n",
    "        pca_obj = PCA().fit(X)\n",
    "        self.scores = pca_obj.transform(X)\n",
    "        self.components = pca_obj.components_\n",
    "\n",
    "        return self.scores[:,1-M].reshape(X.shape[0],M) @self.components[:M][0].reshape(M,X.shape[1])\n",
    "\n",
    "    \n",
    "    def iterfill(self, M=1, thresh=1e-7):\n",
    "        hat_data = self.na_data.copy()\n",
    "        bar_data = np.nanmean(hat_data, axis=0)\n",
    "        hat_data[self.r_idx, self.c_idx] = bar_data[self.c_idx]\n",
    "        \n",
    "        rel_err = 1\n",
    "        count = 0\n",
    "        ismiss = np.isnan(self.na_data)\n",
    "        mssold = np.mean(hat_data[~ismiss]**2)\n",
    "        mss0 = np.mean(self.na_data[~ismiss]**2)\n",
    "        mssold\n",
    "\n",
    "        while rel_err > thresh:\n",
    "            count += 1\n",
    "            app_data = self.run_pca(hat_data, M)\n",
    "            hat_data[ismiss] = app_data[ismiss]\n",
    "            mss = np.mean(((self.na_data - app_data)[~ismiss])**2)\n",
    "            rel_err = (mssold - mss) / mss0\n",
    "            mssold = mss\n",
    "            print(\"Iteration: {0}, MSS:{1:.3f}, Rel.Err {2:.2e}\".format(count, mss, rel_err))\n",
    "        return hat_data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81a036",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to input NA values and standardize the dataset\n",
    "\n",
    "def make_nas(n,X):\n",
    "    n_omit = n\n",
    "    np.random.seed(15)\n",
    "    ridx = np.random.choice(np.arange(X.shape[0]), n_omit, replace=False)\n",
    "    cidx = np.random.choice(np.arange(X.shape[1]), n_omit, replace=True)\n",
    "    Xna = X.copy()\n",
    "    Xna[ridx, cidx] = np.nan\n",
    "\n",
    "    scaler = StandardScaler(with_std=True, with_mean=True)\n",
    "    Xna_scaled = scaler.fit_transform(Xna)\n",
    "    return ridx, cidx, Xna, Xna_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed25db",
   "metadata": {},
   "source": [
    "#### Filling the NA values on the Hitters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8b3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Hitters.csv\"\n",
    "Hitters = pd.read_csv(url)\n",
    "Hitters = Hitters.set_index('Unnamed: 0')\n",
    "Hitters = Hitters.select_dtypes(include=['number'])\n",
    "X=Hitters.values\n",
    "\n",
    "\n",
    "ridx, cidx, Xna, Xna_scaled = make_nas(50,X)  # input 50 NA values\n",
    "inputter_object = PcaInputter(Xna_scaled)\n",
    "Xinputted = inputter_object.iterfill()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(Xna_scaled)\n",
    "print(\"\\n\")\n",
    "print(Xinputted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75607132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#correlation of the original values with the inputted values\n",
    "# result is nan, because the original data contains nan values\n",
    "scaler = StandardScaler(with_std=True, with_mean=True)\n",
    "original_data= scaler.fit(Xna).transform(X)\n",
    "np.corrcoef(original_data[ridx, cidx], Xinputted[ridx, cidx])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd7ccb",
   "metadata": {},
   "source": [
    "#### Filling the NA values on the Auto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90348db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Auto.csv\"\n",
    "Auto = pd.read_csv(url)\n",
    "Auto = Auto.set_index('name')\n",
    "Auto = Auto.select_dtypes(include=['number'])\n",
    "X=Auto.values\n",
    "ridx, cidx, Xna, Xna_scaled = make_nas(50,X)\n",
    "inputter_object = PcaInputter(Xna_scaled)\n",
    "Xinputted = inputter_object.iterfill()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(Xna_scaled)\n",
    "print(\"\\n\")\n",
    "print(Xinputted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebf572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation of the original values with the inputted values\n",
    "scaler = StandardScaler(with_std=True, with_mean=True)\n",
    "original_data= scaler.fit(Xna).transform(X)\n",
    "np.corrcoef(original_data[ridx, cidx], Xinputted[ridx, cidx])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b05cf7",
   "metadata": {},
   "source": [
    "#### Filling the NA values on the Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343445ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Boston.csv\"\n",
    "Boston = pd.read_csv(url)\n",
    "X=Boston.values\n",
    "\n",
    "ridx, cidx, Xna, Xna_scaled = make_nas(10,X)\n",
    "inputter_object = PcaInputter(Xna_scaled)\n",
    "Xinputted = inputter_object.iterfill()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(Xna_scaled)\n",
    "print(\"\\n\")\n",
    "print(Xinputted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation of the original values with the inputted values\n",
    "scaler = StandardScaler(with_std=True, with_mean=True)\n",
    "original_data= scaler.fit(Xna).transform(X)\n",
    "np.corrcoef(original_data[ridx, cidx], Xinputted[ridx, cidx])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2afe68",
   "metadata": {},
   "source": [
    "#### Filling the NA values on the US arrests dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/USArrests.csv\"\n",
    "USArrests = pd.read_csv(url)\n",
    "USArrests = USArrests.set_index('Unnamed: 0')\n",
    "\n",
    "X = USArrests.values\n",
    "\n",
    "ridx, cidx, Xna, Xna_scaled = make_nas(20,X)\n",
    "\n",
    "inputter_object = PcaInputter(Xna_scaled)\n",
    "Xinputted = inputter_object.iterfill()\n",
    "\n",
    "print(Xna_scaled)\n",
    "print(\"/n\")\n",
    "print(Xinputted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation of the original values with the inputted values\n",
    "scaler = StandardScaler(with_std=True, with_mean=True)\n",
    "original_data= scaler.fit(Xna).transform(X)\n",
    "np.corrcoef(original_data[ridx, cidx], Xinputted[ridx, cidx])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38446c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca_inputter",
   "language": "python",
   "name": "pca_inputter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
